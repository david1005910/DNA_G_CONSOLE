# ML 분류 시스템 기술 심층 분석

DNA 분류 모델이 사용하는 Type A/B 정의, 데이터 근거, 3-gram 패턴 분석 기법, RandomForestClassifier 알고리즘에 대한 상세 기술 문서입니다.

---

## 1. Type A / Type B 분류 기준

### 정의

이 시스템에서 **Type A와 Type B**는 **특정 유전 패턴(Motif)의 출현 빈도**에 따라 정의됩니다.

| 분류 | 정의 | 의미 |
|:---|:---|:---|
| **Type A** | DNA 서열 내 `GCG` 패턴이 **5회 이상** 출현 | GC-rich 영역 다수 포함. 일반적으로 안정적인 이중 나선 구조를 형성하며, 특정 유전자 조절 영역(프로모터 등)에서 자주 발견됨. |
| **Type B** | DNA 서열 내 `GCG` 패턴이 **5회 미만** 출현 | GC 함량이 낮은 서열. AT-rich 영역이 많아 상대적으로 덜 안정적인 구조를 가짐. |

### 코드 근거 (`train_model.py` 73번째 줄)

```python
labels = ["Type A" if seq.count("GCG") >= 5 else "Type B" for seq in sequences]
```

> ⚠️ **주의**: 이 분류 기준은 **시뮬레이션 목적**으로 설정된 것입니다. 실제 바이오 연구에서는 전문가의 라벨링 또는 실험 데이터 기반 분류가 필요합니다.

---

## 2. 학습에 사용된 데이터

### 데이터 소스

- **NCBI (National Center for Biotechnology Information)**: 미국 국립생물정보센터의 공개 데이터베이스.
- **수집 조건**:
  - Organism: `Viruses` (바이러스)
  - Sequence Length: `200~1000 bp`
  - Molecule Type: `genomic DNA` 또는 `mRNA`

### 데이터 수집 API (`record_service.py`)

```python
term = "Viruses[Organism] AND 200:1000[SLEN] AND biomol_genomic[PROP]"
```

### 데이터 저장

- **테이블**: `genetic_records` (SQLite)
- **주요 필드**:
  - `dna_sequence`: 실제 염기 서열 (A, T, C, G 문자열)
  - `record_type`: DNA 또는 RNA
  - `occurrence_count`: 동일 서열 출현 횟수 (학습 가중치로 활용)

---

## 3. 3-gram (Tri-gram) 패턴 분석

### 3-gram이란?

DNA 서열을 **연속된 3개 문자 단위로 분할**하여 빈도를 분석하는 기법입니다.

### 예시

```
서열: ATGCGTACG

3-gram 분할:
- ATG
- TGC
- GCG
- CGT
- GTA
- TAC
- ACG
```

### 왜 3-gram을 사용하는가?

1. **코돈(Codon) 단위 분석**: 유전자의 단백질 합성은 3개 염기 단위(코돈)로 이루어지므로, 3-gram이 생물학적으로 의미 있는 단위.
2. **패턴 발견**: 특정 3-gram 조합이 바이러스 종류나 특성과 연관될 수 있음.
3. **차원 축소**: 가능한 3-gram 조합은 4³ = 64가지로, 효율적인 벡터화 가능.

### 코드 구현 (`train_model.py`)

```python
Pipeline([
    ('vectorizer', CountVectorizer(analyzer='char', ngram_range=(3, 3))),
    ('classifier', RandomForestClassifier(n_estimators=100))
])
```

---

## 4. RandomForestClassifier 상세 설명

### 개념

**RandomForest**(**랜덤 포레스트**)는 여러 개의 **결정 트리**(**Decision Tree**)를 생성하고, 각 트리의 예측 결과를 **다수결**(**Voting**)로 취합하여 최종 결과를 산출하는 **앙상블**(**Ensemble**) **학습** 알고리즘입니다.

### 작동 원리

```
            [원본 데이터]
                 |
    +------------+------------+
    |            |            |
  [Tree 1]    [Tree 2]   ... [Tree N]
    |            |            |
 Type A       Type B      Type A
    |            |            |
    +------------+------------+
                 |
         [다수결: Type A]
```

1. **Bootstrap Sampling**: 원본 데이터에서 랜덤하게 복원 추출하여 각 트리에 다른 학습 데이터 제공.
2. **Feature Randomness**: 각 분기점에서 모든 특징이 아닌 **랜덤하게 선택된 특징**만 고려.
3. **Voting**: 모든 트리의 예측을 모아 가장 많이 나온 클래스를 최종 선택.

### 장점

- **과적합(Overfitting) 방지**: 여러 트리의 평균화로 단일 트리보다 일반화 성능 우수.
- **특징 중요도 산출**: 각 특징(3-gram 패턴)이 분류에 얼마나 기여하는지 수치화 가능.
- **해석 가능성**: XAI(Explainable AI) 적용에 적합.

### 파라미터 설정

```python
RandomForestClassifier(
    n_estimators=100,  # 트리 개수
    random_state=42    # 재현 가능성 보장
)
```

### Feature Importance (특징 중요도)

이 시스템의 **Neural Inspector** 화면에서 볼 수 있는 "Top Features"는 바로 이 RandomForest의 `feature_importances_` 속성에서 추출한 것입니다.

```python
importances = classifier.feature_importances_
```

예시 출력:

| 패턴 | 중요도 |
|:---|:---|
| GCG | 0.15 |
| ATG | 0.08 |
| CGT | 0.05 |

---

## 5. 요약: 데이터 흐름

```
[NCBI 크롤링] 
     ↓
[genetics.db 저장]
     ↓
[3-gram 벡터화] → CountVectorizer
     ↓
[RandomForest 학습]
     ↓
[모델 저장: dna_classifier.joblib]
     ↓
[실시간 예측 + 특징 중요도 시각화]
```

---

*Generated by Antigravity AI Engine - Technical Documentation*
